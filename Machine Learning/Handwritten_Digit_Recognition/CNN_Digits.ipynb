{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:01<00:00, 6.22MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 245kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 2.26MB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<?, ?B/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root='data',\n",
    "    train = True,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root='data',\n",
    "    train = False,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x19cb8819490>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x19cbe2c7470>}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders = {\n",
    "    \"train\" : DataLoader(train_data,\n",
    "                        batch_size=102,\n",
    "                        shuffle=True,\n",
    "                        num_workers=1),\n",
    "\n",
    "    \"test\" : DataLoader(test_data,\n",
    "                        batch_size=102,\n",
    "                        shuffle=True,\n",
    "                        num_workers=1)\n",
    "}\n",
    "loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1,10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10,20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50,10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x),2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)),2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)    \n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return F.softmax(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = CNN().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "loss_fc = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fc(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 20 == 0:\n",
    "            print(f\"Train Epoch: {epoch} [{batch_idx*len(data)}/{len(loaders['train'].dataset)} ({100. * batch_idx / len(loaders['train']):.0f}%)]\\t{loss.item():.6f}\")\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in loaders['test']:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += loss_fc(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(loaders['test'].dataset)\n",
    "    print(f\"\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(loaders['test'].dataset)} ({100. * correct/len(loaders['test'].dataset):.0f})%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Home\\AppData\\Local\\Temp\\ipykernel_11268\\102621789.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\t2.303082\n",
      "Train Epoch: 1 [2040/60000 (3%)]\t2.287991\n",
      "Train Epoch: 1 [4080/60000 (7%)]\t2.144021\n",
      "Train Epoch: 1 [6120/60000 (10%)]\t2.040195\n",
      "Train Epoch: 1 [8160/60000 (14%)]\t1.928551\n",
      "Train Epoch: 1 [10200/60000 (17%)]\t1.791826\n",
      "Train Epoch: 1 [12240/60000 (20%)]\t1.801930\n",
      "Train Epoch: 1 [14280/60000 (24%)]\t1.745173\n",
      "Train Epoch: 1 [16320/60000 (27%)]\t1.764813\n",
      "Train Epoch: 1 [18360/60000 (31%)]\t1.749981\n",
      "Train Epoch: 1 [20400/60000 (34%)]\t1.725268\n",
      "Train Epoch: 1 [22440/60000 (37%)]\t1.643504\n",
      "Train Epoch: 1 [24480/60000 (41%)]\t1.699190\n",
      "Train Epoch: 1 [26520/60000 (44%)]\t1.727812\n",
      "Train Epoch: 1 [28560/60000 (48%)]\t1.703591\n",
      "Train Epoch: 1 [30600/60000 (51%)]\t1.634547\n",
      "Train Epoch: 1 [32640/60000 (54%)]\t1.672185\n",
      "Train Epoch: 1 [34680/60000 (58%)]\t1.652503\n",
      "Train Epoch: 1 [36720/60000 (61%)]\t1.607160\n",
      "Train Epoch: 1 [38760/60000 (65%)]\t1.629075\n",
      "Train Epoch: 1 [40800/60000 (68%)]\t1.637678\n",
      "Train Epoch: 1 [42840/60000 (71%)]\t1.614364\n",
      "Train Epoch: 1 [44880/60000 (75%)]\t1.632585\n",
      "Train Epoch: 1 [46920/60000 (78%)]\t1.653716\n",
      "Train Epoch: 1 [48960/60000 (81%)]\t1.639757\n",
      "Train Epoch: 1 [51000/60000 (85%)]\t1.652934\n",
      "Train Epoch: 1 [53040/60000 (88%)]\t1.605673\n",
      "Train Epoch: 1 [55080/60000 (92%)]\t1.605312\n",
      "Train Epoch: 1 [57120/60000 (95%)]\t1.566481\n",
      "Train Epoch: 1 [59160/60000 (98%)]\t1.678757\n",
      "\n",
      "Test set: Average loss: 0.0152, Accuracy: 9288/10000 (93)%\n",
      "Train Epoch: 2 [0/60000 (0%)]\t1.589087\n",
      "Train Epoch: 2 [2040/60000 (3%)]\t1.631148\n",
      "Train Epoch: 2 [4080/60000 (7%)]\t1.588212\n",
      "Train Epoch: 2 [6120/60000 (10%)]\t1.614015\n",
      "Train Epoch: 2 [8160/60000 (14%)]\t1.620678\n",
      "Train Epoch: 2 [10200/60000 (17%)]\t1.599120\n",
      "Train Epoch: 2 [12240/60000 (20%)]\t1.594635\n",
      "Train Epoch: 2 [14280/60000 (24%)]\t1.585021\n",
      "Train Epoch: 2 [16320/60000 (27%)]\t1.637544\n",
      "Train Epoch: 2 [18360/60000 (31%)]\t1.578799\n",
      "Train Epoch: 2 [20400/60000 (34%)]\t1.637217\n",
      "Train Epoch: 2 [22440/60000 (37%)]\t1.586527\n",
      "Train Epoch: 2 [24480/60000 (41%)]\t1.603964\n",
      "Train Epoch: 2 [26520/60000 (44%)]\t1.551924\n",
      "Train Epoch: 2 [28560/60000 (48%)]\t1.582008\n",
      "Train Epoch: 2 [30600/60000 (51%)]\t1.616959\n",
      "Train Epoch: 2 [32640/60000 (54%)]\t1.591794\n",
      "Train Epoch: 2 [34680/60000 (58%)]\t1.537556\n",
      "Train Epoch: 2 [36720/60000 (61%)]\t1.584083\n",
      "Train Epoch: 2 [38760/60000 (65%)]\t1.569781\n",
      "Train Epoch: 2 [40800/60000 (68%)]\t1.598449\n",
      "Train Epoch: 2 [42840/60000 (71%)]\t1.567736\n",
      "Train Epoch: 2 [44880/60000 (75%)]\t1.553083\n",
      "Train Epoch: 2 [46920/60000 (78%)]\t1.576704\n",
      "Train Epoch: 2 [48960/60000 (81%)]\t1.575665\n",
      "Train Epoch: 2 [51000/60000 (85%)]\t1.555142\n",
      "Train Epoch: 2 [53040/60000 (88%)]\t1.571102\n",
      "Train Epoch: 2 [55080/60000 (92%)]\t1.550419\n",
      "Train Epoch: 2 [57120/60000 (95%)]\t1.546895\n",
      "Train Epoch: 2 [59160/60000 (98%)]\t1.574462\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy: 9454/10000 (95)%\n",
      "Train Epoch: 3 [0/60000 (0%)]\t1.546340\n",
      "Train Epoch: 3 [2040/60000 (3%)]\t1.585379\n",
      "Train Epoch: 3 [4080/60000 (7%)]\t1.529258\n",
      "Train Epoch: 3 [6120/60000 (10%)]\t1.572139\n",
      "Train Epoch: 3 [8160/60000 (14%)]\t1.603586\n",
      "Train Epoch: 3 [10200/60000 (17%)]\t1.593773\n",
      "Train Epoch: 3 [12240/60000 (20%)]\t1.603583\n",
      "Train Epoch: 3 [14280/60000 (24%)]\t1.586553\n",
      "Train Epoch: 3 [16320/60000 (27%)]\t1.605304\n",
      "Train Epoch: 3 [18360/60000 (31%)]\t1.591365\n",
      "Train Epoch: 3 [20400/60000 (34%)]\t1.586730\n",
      "Train Epoch: 3 [22440/60000 (37%)]\t1.586321\n",
      "Train Epoch: 3 [24480/60000 (41%)]\t1.570183\n",
      "Train Epoch: 3 [26520/60000 (44%)]\t1.582479\n",
      "Train Epoch: 3 [28560/60000 (48%)]\t1.561184\n",
      "Train Epoch: 3 [30600/60000 (51%)]\t1.590457\n",
      "Train Epoch: 3 [32640/60000 (54%)]\t1.565186\n",
      "Train Epoch: 3 [34680/60000 (58%)]\t1.580428\n",
      "Train Epoch: 3 [36720/60000 (61%)]\t1.547875\n",
      "Train Epoch: 3 [38760/60000 (65%)]\t1.543784\n",
      "Train Epoch: 3 [40800/60000 (68%)]\t1.573979\n",
      "Train Epoch: 3 [42840/60000 (71%)]\t1.571113\n",
      "Train Epoch: 3 [44880/60000 (75%)]\t1.574822\n",
      "Train Epoch: 3 [46920/60000 (78%)]\t1.540863\n",
      "Train Epoch: 3 [48960/60000 (81%)]\t1.576004\n",
      "Train Epoch: 3 [51000/60000 (85%)]\t1.570510\n",
      "Train Epoch: 3 [53040/60000 (88%)]\t1.578700\n",
      "Train Epoch: 3 [55080/60000 (92%)]\t1.603154\n",
      "Train Epoch: 3 [57120/60000 (95%)]\t1.519792\n",
      "Train Epoch: 3 [59160/60000 (98%)]\t1.548579\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 9533/10000 (95)%\n",
      "Train Epoch: 4 [0/60000 (0%)]\t1.590242\n",
      "Train Epoch: 4 [2040/60000 (3%)]\t1.564578\n",
      "Train Epoch: 4 [4080/60000 (7%)]\t1.615375\n",
      "Train Epoch: 4 [6120/60000 (10%)]\t1.571281\n",
      "Train Epoch: 4 [8160/60000 (14%)]\t1.527089\n",
      "Train Epoch: 4 [10200/60000 (17%)]\t1.565270\n",
      "Train Epoch: 4 [12240/60000 (20%)]\t1.521833\n",
      "Train Epoch: 4 [14280/60000 (24%)]\t1.591320\n",
      "Train Epoch: 4 [16320/60000 (27%)]\t1.572343\n",
      "Train Epoch: 4 [18360/60000 (31%)]\t1.580481\n",
      "Train Epoch: 4 [20400/60000 (34%)]\t1.574189\n",
      "Train Epoch: 4 [22440/60000 (37%)]\t1.545401\n",
      "Train Epoch: 4 [24480/60000 (41%)]\t1.578328\n",
      "Train Epoch: 4 [26520/60000 (44%)]\t1.555659\n",
      "Train Epoch: 4 [28560/60000 (48%)]\t1.558499\n",
      "Train Epoch: 4 [30600/60000 (51%)]\t1.542539\n",
      "Train Epoch: 4 [32640/60000 (54%)]\t1.571123\n",
      "Train Epoch: 4 [34680/60000 (58%)]\t1.566947\n",
      "Train Epoch: 4 [36720/60000 (61%)]\t1.555146\n",
      "Train Epoch: 4 [38760/60000 (65%)]\t1.559944\n",
      "Train Epoch: 4 [40800/60000 (68%)]\t1.544116\n",
      "Train Epoch: 4 [42840/60000 (71%)]\t1.519777\n",
      "Train Epoch: 4 [44880/60000 (75%)]\t1.566571\n",
      "Train Epoch: 4 [46920/60000 (78%)]\t1.531782\n",
      "Train Epoch: 4 [48960/60000 (81%)]\t1.512397\n",
      "Train Epoch: 4 [51000/60000 (85%)]\t1.596380\n",
      "Train Epoch: 4 [53040/60000 (88%)]\t1.528995\n",
      "Train Epoch: 4 [55080/60000 (92%)]\t1.581654\n",
      "Train Epoch: 4 [57120/60000 (95%)]\t1.578431\n",
      "Train Epoch: 4 [59160/60000 (98%)]\t1.582909\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 9592/10000 (96)%\n",
      "Train Epoch: 5 [0/60000 (0%)]\t1.574501\n",
      "Train Epoch: 5 [2040/60000 (3%)]\t1.525106\n",
      "Train Epoch: 5 [4080/60000 (7%)]\t1.543604\n",
      "Train Epoch: 5 [6120/60000 (10%)]\t1.585604\n",
      "Train Epoch: 5 [8160/60000 (14%)]\t1.564295\n",
      "Train Epoch: 5 [10200/60000 (17%)]\t1.544217\n",
      "Train Epoch: 5 [12240/60000 (20%)]\t1.554286\n",
      "Train Epoch: 5 [14280/60000 (24%)]\t1.583473\n",
      "Train Epoch: 5 [16320/60000 (27%)]\t1.552557\n",
      "Train Epoch: 5 [18360/60000 (31%)]\t1.551800\n",
      "Train Epoch: 5 [20400/60000 (34%)]\t1.583598\n",
      "Train Epoch: 5 [22440/60000 (37%)]\t1.533335\n",
      "Train Epoch: 5 [24480/60000 (41%)]\t1.558366\n",
      "Train Epoch: 5 [26520/60000 (44%)]\t1.563295\n",
      "Train Epoch: 5 [28560/60000 (48%)]\t1.539674\n",
      "Train Epoch: 5 [30600/60000 (51%)]\t1.550098\n",
      "Train Epoch: 5 [32640/60000 (54%)]\t1.545700\n",
      "Train Epoch: 5 [34680/60000 (58%)]\t1.521308\n",
      "Train Epoch: 5 [36720/60000 (61%)]\t1.545508\n",
      "Train Epoch: 5 [38760/60000 (65%)]\t1.617490\n",
      "Train Epoch: 5 [40800/60000 (68%)]\t1.571232\n",
      "Train Epoch: 5 [42840/60000 (71%)]\t1.521076\n",
      "Train Epoch: 5 [44880/60000 (75%)]\t1.571056\n",
      "Train Epoch: 5 [46920/60000 (78%)]\t1.542477\n",
      "Train Epoch: 5 [48960/60000 (81%)]\t1.512569\n",
      "Train Epoch: 5 [51000/60000 (85%)]\t1.544783\n",
      "Train Epoch: 5 [53040/60000 (88%)]\t1.545399\n",
      "Train Epoch: 5 [55080/60000 (92%)]\t1.510266\n",
      "Train Epoch: 5 [57120/60000 (95%)]\t1.541228\n",
      "Train Epoch: 5 [59160/60000 (98%)]\t1.554500\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy: 9628/10000 (96)%\n",
      "Train Epoch: 6 [0/60000 (0%)]\t1.519710\n",
      "Train Epoch: 6 [2040/60000 (3%)]\t1.568910\n",
      "Train Epoch: 6 [4080/60000 (7%)]\t1.510422\n",
      "Train Epoch: 6 [6120/60000 (10%)]\t1.575093\n",
      "Train Epoch: 6 [8160/60000 (14%)]\t1.541746\n",
      "Train Epoch: 6 [10200/60000 (17%)]\t1.574019\n",
      "Train Epoch: 6 [12240/60000 (20%)]\t1.563444\n",
      "Train Epoch: 6 [14280/60000 (24%)]\t1.577180\n",
      "Train Epoch: 6 [16320/60000 (27%)]\t1.542830\n",
      "Train Epoch: 6 [18360/60000 (31%)]\t1.543091\n",
      "Train Epoch: 6 [20400/60000 (34%)]\t1.559154\n",
      "Train Epoch: 6 [22440/60000 (37%)]\t1.525647\n",
      "Train Epoch: 6 [24480/60000 (41%)]\t1.564525\n",
      "Train Epoch: 6 [26520/60000 (44%)]\t1.574065\n",
      "Train Epoch: 6 [28560/60000 (48%)]\t1.539841\n",
      "Train Epoch: 6 [30600/60000 (51%)]\t1.533636\n",
      "Train Epoch: 6 [32640/60000 (54%)]\t1.568977\n",
      "Train Epoch: 6 [34680/60000 (58%)]\t1.599465\n",
      "Train Epoch: 6 [36720/60000 (61%)]\t1.535674\n",
      "Train Epoch: 6 [38760/60000 (65%)]\t1.513420\n",
      "Train Epoch: 6 [40800/60000 (68%)]\t1.564606\n",
      "Train Epoch: 6 [42840/60000 (71%)]\t1.534349\n",
      "Train Epoch: 6 [44880/60000 (75%)]\t1.544166\n",
      "Train Epoch: 6 [46920/60000 (78%)]\t1.531942\n",
      "Train Epoch: 6 [48960/60000 (81%)]\t1.518641\n",
      "Train Epoch: 6 [51000/60000 (85%)]\t1.546808\n",
      "Train Epoch: 6 [53040/60000 (88%)]\t1.572523\n",
      "Train Epoch: 6 [55080/60000 (92%)]\t1.522010\n",
      "Train Epoch: 6 [57120/60000 (95%)]\t1.531469\n",
      "Train Epoch: 6 [59160/60000 (98%)]\t1.510694\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy: 9630/10000 (96)%\n",
      "Train Epoch: 7 [0/60000 (0%)]\t1.588738\n",
      "Train Epoch: 7 [2040/60000 (3%)]\t1.542470\n",
      "Train Epoch: 7 [4080/60000 (7%)]\t1.566277\n",
      "Train Epoch: 7 [6120/60000 (10%)]\t1.511344\n",
      "Train Epoch: 7 [8160/60000 (14%)]\t1.578171\n",
      "Train Epoch: 7 [10200/60000 (17%)]\t1.554572\n",
      "Train Epoch: 7 [12240/60000 (20%)]\t1.551224\n",
      "Train Epoch: 7 [14280/60000 (24%)]\t1.520902\n",
      "Train Epoch: 7 [16320/60000 (27%)]\t1.550350\n",
      "Train Epoch: 7 [18360/60000 (31%)]\t1.503554\n",
      "Train Epoch: 7 [20400/60000 (34%)]\t1.561405\n",
      "Train Epoch: 7 [22440/60000 (37%)]\t1.510692\n",
      "Train Epoch: 7 [24480/60000 (41%)]\t1.520715\n",
      "Train Epoch: 7 [26520/60000 (44%)]\t1.574337\n",
      "Train Epoch: 7 [28560/60000 (48%)]\t1.563007\n",
      "Train Epoch: 7 [30600/60000 (51%)]\t1.561426\n",
      "Train Epoch: 7 [32640/60000 (54%)]\t1.544514\n",
      "Train Epoch: 7 [34680/60000 (58%)]\t1.502585\n",
      "Train Epoch: 7 [36720/60000 (61%)]\t1.514931\n",
      "Train Epoch: 7 [38760/60000 (65%)]\t1.516527\n",
      "Train Epoch: 7 [40800/60000 (68%)]\t1.548854\n",
      "Train Epoch: 7 [42840/60000 (71%)]\t1.538268\n",
      "Train Epoch: 7 [44880/60000 (75%)]\t1.551873\n",
      "Train Epoch: 7 [46920/60000 (78%)]\t1.563143\n",
      "Train Epoch: 7 [48960/60000 (81%)]\t1.568785\n",
      "Train Epoch: 7 [51000/60000 (85%)]\t1.533421\n",
      "Train Epoch: 7 [53040/60000 (88%)]\t1.561144\n",
      "Train Epoch: 7 [55080/60000 (92%)]\t1.563086\n",
      "Train Epoch: 7 [57120/60000 (95%)]\t1.531312\n",
      "Train Epoch: 7 [59160/60000 (98%)]\t1.538871\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy: 9672/10000 (97)%\n",
      "Train Epoch: 8 [0/60000 (0%)]\t1.555458\n",
      "Train Epoch: 8 [2040/60000 (3%)]\t1.517843\n",
      "Train Epoch: 8 [4080/60000 (7%)]\t1.524985\n",
      "Train Epoch: 8 [6120/60000 (10%)]\t1.509638\n",
      "Train Epoch: 8 [8160/60000 (14%)]\t1.598432\n",
      "Train Epoch: 8 [10200/60000 (17%)]\t1.498496\n",
      "Train Epoch: 8 [12240/60000 (20%)]\t1.517433\n",
      "Train Epoch: 8 [14280/60000 (24%)]\t1.575342\n",
      "Train Epoch: 8 [16320/60000 (27%)]\t1.543456\n",
      "Train Epoch: 8 [18360/60000 (31%)]\t1.496372\n",
      "Train Epoch: 8 [20400/60000 (34%)]\t1.495533\n",
      "Train Epoch: 8 [22440/60000 (37%)]\t1.518286\n",
      "Train Epoch: 8 [24480/60000 (41%)]\t1.595889\n",
      "Train Epoch: 8 [26520/60000 (44%)]\t1.563459\n",
      "Train Epoch: 8 [28560/60000 (48%)]\t1.520091\n",
      "Train Epoch: 8 [30600/60000 (51%)]\t1.543390\n",
      "Train Epoch: 8 [32640/60000 (54%)]\t1.507751\n",
      "Train Epoch: 8 [34680/60000 (58%)]\t1.515042\n",
      "Train Epoch: 8 [36720/60000 (61%)]\t1.560958\n",
      "Train Epoch: 8 [38760/60000 (65%)]\t1.570073\n",
      "Train Epoch: 8 [40800/60000 (68%)]\t1.547402\n",
      "Train Epoch: 8 [42840/60000 (71%)]\t1.521648\n",
      "Train Epoch: 8 [44880/60000 (75%)]\t1.541764\n",
      "Train Epoch: 8 [46920/60000 (78%)]\t1.543051\n",
      "Train Epoch: 8 [48960/60000 (81%)]\t1.549122\n",
      "Train Epoch: 8 [51000/60000 (85%)]\t1.550104\n",
      "Train Epoch: 8 [53040/60000 (88%)]\t1.561932\n",
      "Train Epoch: 8 [55080/60000 (92%)]\t1.574864\n",
      "Train Epoch: 8 [57120/60000 (95%)]\t1.522426\n",
      "Train Epoch: 8 [59160/60000 (98%)]\t1.559197\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy: 9681/10000 (97)%\n",
      "Train Epoch: 9 [0/60000 (0%)]\t1.565543\n",
      "Train Epoch: 9 [2040/60000 (3%)]\t1.531913\n",
      "Train Epoch: 9 [4080/60000 (7%)]\t1.511461\n",
      "Train Epoch: 9 [6120/60000 (10%)]\t1.533187\n",
      "Train Epoch: 9 [8160/60000 (14%)]\t1.529730\n",
      "Train Epoch: 9 [10200/60000 (17%)]\t1.532950\n",
      "Train Epoch: 9 [12240/60000 (20%)]\t1.539848\n",
      "Train Epoch: 9 [14280/60000 (24%)]\t1.541140\n",
      "Train Epoch: 9 [16320/60000 (27%)]\t1.534122\n",
      "Train Epoch: 9 [18360/60000 (31%)]\t1.562009\n",
      "Train Epoch: 9 [20400/60000 (34%)]\t1.565516\n",
      "Train Epoch: 9 [22440/60000 (37%)]\t1.580567\n",
      "Train Epoch: 9 [24480/60000 (41%)]\t1.499422\n",
      "Train Epoch: 9 [26520/60000 (44%)]\t1.504981\n",
      "Train Epoch: 9 [28560/60000 (48%)]\t1.513792\n",
      "Train Epoch: 9 [30600/60000 (51%)]\t1.541114\n",
      "Train Epoch: 9 [32640/60000 (54%)]\t1.589857\n",
      "Train Epoch: 9 [34680/60000 (58%)]\t1.530880\n",
      "Train Epoch: 9 [36720/60000 (61%)]\t1.613352\n",
      "Train Epoch: 9 [38760/60000 (65%)]\t1.513832\n",
      "Train Epoch: 9 [40800/60000 (68%)]\t1.516903\n",
      "Train Epoch: 9 [42840/60000 (71%)]\t1.516227\n",
      "Train Epoch: 9 [44880/60000 (75%)]\t1.547377\n",
      "Train Epoch: 9 [46920/60000 (78%)]\t1.503441\n",
      "Train Epoch: 9 [48960/60000 (81%)]\t1.524802\n",
      "Train Epoch: 9 [51000/60000 (85%)]\t1.501830\n",
      "Train Epoch: 9 [53040/60000 (88%)]\t1.534211\n",
      "Train Epoch: 9 [55080/60000 (92%)]\t1.501269\n",
      "Train Epoch: 9 [57120/60000 (95%)]\t1.530220\n",
      "Train Epoch: 9 [59160/60000 (98%)]\t1.502449\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy: 9726/10000 (97)%\n",
      "Train Epoch: 10 [0/60000 (0%)]\t1.540479\n",
      "Train Epoch: 10 [2040/60000 (3%)]\t1.527320\n",
      "Train Epoch: 10 [4080/60000 (7%)]\t1.541212\n",
      "Train Epoch: 10 [6120/60000 (10%)]\t1.514549\n",
      "Train Epoch: 10 [8160/60000 (14%)]\t1.500486\n",
      "Train Epoch: 10 [10200/60000 (17%)]\t1.544663\n",
      "Train Epoch: 10 [12240/60000 (20%)]\t1.530425\n",
      "Train Epoch: 10 [14280/60000 (24%)]\t1.538848\n",
      "Train Epoch: 10 [16320/60000 (27%)]\t1.534474\n",
      "Train Epoch: 10 [18360/60000 (31%)]\t1.533522\n",
      "Train Epoch: 10 [20400/60000 (34%)]\t1.507470\n",
      "Train Epoch: 10 [22440/60000 (37%)]\t1.548668\n",
      "Train Epoch: 10 [24480/60000 (41%)]\t1.514890\n",
      "Train Epoch: 10 [26520/60000 (44%)]\t1.543414\n",
      "Train Epoch: 10 [28560/60000 (48%)]\t1.550941\n",
      "Train Epoch: 10 [30600/60000 (51%)]\t1.555756\n",
      "Train Epoch: 10 [32640/60000 (54%)]\t1.562429\n",
      "Train Epoch: 10 [34680/60000 (58%)]\t1.510972\n",
      "Train Epoch: 10 [36720/60000 (61%)]\t1.537912\n",
      "Train Epoch: 10 [38760/60000 (65%)]\t1.561027\n",
      "Train Epoch: 10 [40800/60000 (68%)]\t1.550167\n",
      "Train Epoch: 10 [42840/60000 (71%)]\t1.527479\n",
      "Train Epoch: 10 [44880/60000 (75%)]\t1.519003\n",
      "Train Epoch: 10 [46920/60000 (78%)]\t1.551767\n",
      "Train Epoch: 10 [48960/60000 (81%)]\t1.515026\n",
      "Train Epoch: 10 [51000/60000 (85%)]\t1.538986\n",
      "Train Epoch: 10 [53040/60000 (88%)]\t1.503574\n",
      "Train Epoch: 10 [55080/60000 (92%)]\t1.508596\n",
      "Train Epoch: 10 [57120/60000 (95%)]\t1.534155\n",
      "Train Epoch: 10 [59160/60000 (98%)]\t1.531681\n",
      "\n",
      "Test set: Average loss: 0.0147, Accuracy: 9731/10000 (97)%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1,11):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Home\\AppData\\Local\\Temp\\ipykernel_11268\\102621789.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "data, target = test_data[6]\n",
    "\n",
    "data = data.unsqueeze(0).to(device)\n",
    "output = model(data)\n",
    "\n",
    "pred = output.argmax(dim = 1, keepdim = True).item()\n",
    "\n",
    "print(f\"Prediction: \", pred)\n",
    "\n",
    "image = data.squeeze(0).squeeze(0).cpu().numpy()\n",
    "plt.imshow(image,cmap='gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
